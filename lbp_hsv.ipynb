{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1105687,"sourceType":"datasetVersion","datasetId":619181}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import thư viện","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nfrom collections import Counter\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm\nimport random\nimport matplotlib.gridspec as gridspec\nimport numpy as np\nfrom skimage.feature import hog, local_binary_pattern\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nimport cudf  # Thư viện tương tự pandas cho GPU\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport itertools\nfrom cuml.svm import SVC as cuSVC\nfrom cuml.ensemble import RandomForestClassifier as cuRF\nfrom cuml.neighbors import KNeighborsClassifier as cuKNN\nfrom cuml.metrics import accuracy_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import KernelPCA\nimport logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:17:48.336766Z","iopub.execute_input":"2025-05-20T13:17:48.336943Z","iopub.status.idle":"2025-05-20T13:18:01.167948Z","shell.execute_reply.started":"2025-05-20T13:17:48.336928Z","shell.execute_reply":"2025-05-20T13:18:01.167355Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Chuẩn bị dữ liệu","metadata":{}},{"cell_type":"code","source":"class ImageFileLabelExtractor:\n    IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.tif'}\n\n    def __init__(self, root_dir):\n        \"\"\"\n        Khởi tạo với thư mục gốc root_dir\n        \"\"\"\n        self.root_dir = root_dir\n\n    def is_image_file(self, filename):\n        \"\"\"\n        Kiểm tra file có phải file ảnh hay không dựa vào phần mở rộng\n        \"\"\"\n        ext = os.path.splitext(filename)[1].lower()\n        return ext in self.IMAGE_EXTENSIONS\n\n    def extract(self):\n        \"\"\"\n        Duyệt qua tất cả các thư mục con, trả về list các tuple (đường_dẫn_file, nhãn)\n        nhãn = tên thư mục chứa file\n        Chỉ lấy các file có định dạng ảnh\n        \"\"\"\n        data = []\n        labels = []\n        for dirpath, dirnames, filenames in os.walk(self.root_dir):\n            label = os.path.basename(dirpath)\n            for file in filenames:\n                if self.is_image_file(file):\n                    file_path = os.path.join(dirpath, file)\n                    data.append(file_path)\n                    labels.append(label)\n\n        df = pd.DataFrame({\n            'file_path': data,\n            'label': labels\n        })\n        return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.169242Z","iopub.execute_input":"2025-05-20T13:18:01.169595Z","iopub.status.idle":"2025-05-20T13:18:01.175483Z","shell.execute_reply.started":"2025-05-20T13:18:01.169570Z","shell.execute_reply":"2025-05-20T13:18:01.174779Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Tiền xử lý dữ liệu","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom typing import List\n\ndef denoise_images(image_list: List[np.ndarray]) -> List[np.ndarray]:\n    \"\"\"\n    Hàm nhận vào danh sách ảnh, giảm nhiễu bằng Median filter và Gaussian Blur,\n    trả về danh sách ảnh đã xử lý.\n    \n    Tham số:\n        image_list (List[np.ndarray]): Danh sách ảnh đầu vào (mỗi ảnh dạng numpy array)\n        \n    Trả về:\n        List[np.ndarray]: Danh sách ảnh sau khi giảm nhiễu\n    \"\"\"\n    denoised_images = []\n    \n    for img in image_list:\n        # Kiểm tra ảnh đầu vào có phải ảnh xám hay ảnh màu\n        if len(img.shape) == 2:\n            # Ảnh xám\n            median = cv2.medianBlur(img, ksize=3)  # kernel size 3 hoặc 5 tùy nhiễu\n            denoised = cv2.GaussianBlur(median, (3,3), sigmaX=0)\n        elif len(img.shape) == 3:\n            # Ảnh màu\n            # Áp dụng từng kênh riêng biệt hoặc chuyển sang không gian khác xử lý\n            median = cv2.medianBlur(img, ksize=3)\n            denoised = cv2.GaussianBlur(median, (3,3), sigmaX=0)\n        else:\n            raise ValueError(\"Ảnh đầu vào không đúng định dạng (2 hoặc 3 chiều)\")\n        \n        denoised_images.append(denoised)\n    \n    return denoised_images\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.176310Z","iopub.execute_input":"2025-05-20T13:18:01.176597Z","iopub.status.idle":"2025-05-20T13:18:01.197818Z","shell.execute_reply.started":"2025-05-20T13:18:01.176580Z","shell.execute_reply":"2025-05-20T13:18:01.197241Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Thống kê dữ liệu","metadata":{}},{"cell_type":"code","source":"def load_images_from_df_cv2(df, target_size=(224, 224)):\n    \"\"\"\n    df: pandas DataFrame với cột 'file_path' và 'label'\n    \n    target_size: Kích thước mới của ảnh sau khi resize (mặc định là (224, 224))\n    \n    Trả về:\n    - DataFrame chứa các ảnh đã resize và nhãn tương ứng.\n    \"\"\"\n    images = []\n    labels = []\n    \n    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading and resizing images\"):\n        try:\n            # Load ảnh bằng cv2 (mặc định ảnh dạng BGR)\n            img = cv2.imread(row['file_path'], cv2.IMREAD_COLOR)\n            if img is None:\n                print(f\"Warning: Không thể load ảnh {row['file_path']}\")\n                continue\n            \n            # Resize ảnh về kích thước target_size\n            img_resized = cv2.resize(img, target_size)\n\n            images.append(img_resized)\n            labels.append(row['label'])\n        except Exception as e:\n            print(f\"Error load ảnh {row['file_path']}: {e}\")\n\n    # Tạo DataFrame chứa ảnh đã resize và nhãn\n    df_resized = pd.DataFrame({\n        'image': images,\n        'label': labels\n    })\n    \n    return df_resized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.198584Z","iopub.execute_input":"2025-05-20T13:18:01.198824Z","iopub.status.idle":"2025-05-20T13:18:01.212682Z","shell.execute_reply.started":"2025-05-20T13:18:01.198802Z","shell.execute_reply":"2025-05-20T13:18:01.212153Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def edit_labels(df, label_column='label', mapping=None, func=None):\n    \"\"\"\n    Chỉnh sửa nhãn trong DataFrame.\n\n    Tham số:\n    - df: pandas DataFrame có cột chứa nhãn\n    - label_column: tên cột chứa nhãn (mặc định 'label')\n    - mapping: dict ánh xạ {nhãn_cũ: nhãn_mới}, nếu có mapping thì dùng để thay nhãn\n    - func: hàm nhận vào nhãn cũ trả về nhãn mới (nếu cần chỉnh sửa phức tạp hơn)\n\n    Trả về:\n    - DataFrame mới với nhãn đã chỉnh sửa\n\n    Chú ý:\n    - Nếu cả mapping và func cùng được truyền vào, sẽ ưu tiên dùng func.\n    \"\"\"\n\n    df_copy = df.copy()\n\n    if func is not None:\n        df_copy[label_column] = df_copy[label_column].apply(func)\n    elif mapping is not None:\n        df_copy[label_column] = df_copy[label_column].map(mapping).fillna(df_copy[label_column])\n\n    return df_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.213272Z","iopub.execute_input":"2025-05-20T13:18:01.213443Z","iopub.status.idle":"2025-05-20T13:18:01.226662Z","shell.execute_reply.started":"2025-05-20T13:18:01.213428Z","shell.execute_reply":"2025-05-20T13:18:01.226069Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class LabelStats:\n    def __init__(self, df):\n        \"\"\"\n        data: list các phần tử (ví dụ: đường dẫn file)\n        labels: list nhãn tương ứng với data\n        \"\"\"\n        self.df = df\n\n    def get_num_classes(self):\n        \"\"\"\n        Trả về số lượng lớp (số nhãn duy nhất)\n        \"\"\"\n        return self.df['label'].nunique()\n\n    def count_per_class(self):\n        \"\"\"\n        Trả về Series thống kê số lượng phần tử của mỗi lớp, index là nhãn\n        \"\"\"\n        return self.df['label'].value_counts()\n\n    def summary(self):\n        \"\"\"\n        In ra tổng quan về số lớp và số lượng từng lớp\n        \"\"\"\n        num_classes = self.get_num_classes()\n        counts = self.count_per_class()\n        print(f\"Tổng số lớp: {num_classes}\")\n        print(\"Số lượng mỗi lớp:\")\n        for label, count in counts.items():\n            print(f\" - Lớp '{label}': {count} phần tử\")\n\n    def plot_class_distribution(self, figsize=(10,6), color='skyblue'):\n        counts = self.count_per_class()\n        plt.figure(figsize=figsize)\n        counts.plot(kind='bar', color=color)\n        plt.xlabel('Class Label')\n        plt.ylabel('Số lượng ảnh')\n        plt.title('Biểu đồ thống kê số lượng ảnh mỗi class')\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.227453Z","iopub.execute_input":"2025-05-20T13:18:01.227760Z","iopub.status.idle":"2025-05-20T13:18:01.242563Z","shell.execute_reply.started":"2025-05-20T13:18:01.227737Z","shell.execute_reply":"2025-05-20T13:18:01.242108Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport random\nimport numpy as np\nfrom PIL import Image\n\ndef plot_images_with_label_column(\n    df, \n    images_col='image', \n    label_col='label', \n    samples_per_class=5, \n    figsize=(18, 2),\n    grayscale=False  # Thêm tham số tùy chọn ảnh xám\n):\n    classes = df[label_col].unique()\n    num_classes = len(classes)\n\n    fig = plt.figure(figsize=(figsize[0], figsize[1]*num_classes))\n    gs = gridspec.GridSpec(num_classes, samples_per_class + 1, width_ratios=[3] + [2]*samples_per_class)\n\n    for row_idx, cls in enumerate(classes):\n        ax_label = fig.add_subplot(gs[row_idx, 0])\n        ax_label.axis('off')\n        ax_label.text(0.5, 0.5, cls, fontsize=12, fontweight='bold', ha='center', va='center')\n\n        class_images = df[df[label_col] == cls][images_col].tolist()\n        sampled_images = random.sample(class_images, min(samples_per_class, len(class_images)))\n\n        for col_idx in range(samples_per_class):\n            ax = fig.add_subplot(gs[row_idx, col_idx + 1])\n            ax.axis('off')\n\n            if col_idx < len(sampled_images):\n                img = sampled_images[col_idx]\n\n                # Nếu là PIL Image, chuyển sang numpy array\n                if isinstance(img, Image.Image):\n                    img = np.array(img)\n\n                if isinstance(img, np.ndarray):\n                    # Nếu ảnh 3 kênh (color), chuyển BGR->RGB nếu cần\n                    if len(img.shape) == 3 and img.shape[2] == 3:\n                        img = img[..., ::-1]  # BGR->RGB giả định ảnh OpenCV\n\n                    if grayscale:\n                        # Nếu ảnh màu, chuyển sang xám\n                        if len(img.shape) == 3:\n                            img_gray = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n                            ax.imshow(img_gray, cmap='gray')\n                        else:\n                            ax.imshow(img, cmap='gray')\n                    else:\n                        # Hiển thị ảnh màu hoặc ảnh xám có sẵn\n                        if len(img.shape) == 2:\n                            ax.imshow(img, cmap='gray')\n                        else:\n                            ax.imshow(img)\n                else:\n                    # Trường hợp khác (list, tensor,...)\n                    ax.imshow(img)\n            else:\n                ax.set_visible(False)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.244777Z","iopub.execute_input":"2025-05-20T13:18:01.244983Z","iopub.status.idle":"2025-05-20T13:18:01.258774Z","shell.execute_reply.started":"2025-05-20T13:18:01.244968Z","shell.execute_reply":"2025-05-20T13:18:01.258175Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Tiền xử lý dữ liệu","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom typing import List\n\ndef denoise_images(image_list: List[np.ndarray]) -> List[np.ndarray]:\n    \"\"\"\n    Hàm nhận vào danh sách ảnh, giảm nhiễu bằng Median filter và Gaussian Blur,\n    trả về danh sách ảnh đã xử lý.\n    \n    Tham số:\n        image_list (List[np.ndarray]): Danh sách ảnh đầu vào (mỗi ảnh dạng numpy array)\n        \n    Trả về:\n        List[np.ndarray]: Danh sách ảnh sau khi giảm nhiễu\n    \"\"\"\n    denoised_images = []\n    \n    for img in image_list:\n        # Kiểm tra ảnh đầu vào có phải ảnh xám hay ảnh màu\n        if len(img.shape) == 2:\n            # Ảnh xám\n            median = cv2.medianBlur(img, ksize=3)  # kernel size 3 hoặc 5 tùy nhiễu\n            denoised = cv2.GaussianBlur(median, (3,3), sigmaX=0)\n        elif len(img.shape) == 3:\n            # Ảnh màu\n            # Áp dụng từng kênh riêng biệt hoặc chuyển sang không gian khác xử lý\n            median = cv2.medianBlur(img, ksize=3)\n            denoised = cv2.GaussianBlur(median, (3,3), sigmaX=0)\n        else:\n            raise ValueError(\"Ảnh đầu vào không đúng định dạng (2 hoặc 3 chiều)\")\n        \n        denoised_images.append(denoised)\n    \n    return denoised_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.259379Z","iopub.execute_input":"2025-05-20T13:18:01.259547Z","iopub.status.idle":"2025-05-20T13:18:01.274634Z","shell.execute_reply.started":"2025-05-20T13:18:01.259533Z","shell.execute_reply":"2025-05-20T13:18:01.273884Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Trích xuất đặc trưng","metadata":{}},{"cell_type":"code","source":"def flatten_images(df, image_col='image', label_col='label'):\n    \"\"\"\n    Hàm làm phẳng ảnh trong DataFrame.\n    \n    Tham số:\n    - df: DataFrame chứa cột 'image' và 'label'.\n    - image_col: tên cột chứa ảnh (mặc định là 'image').\n    - label_col: tên cột chứa nhãn (mặc định là 'label').\n    \n    Trả về:\n    - DataFrame mới với cột 'image_flat' là ảnh đã được làm phẳng và cột 'label' giữ nguyên.\n    \"\"\"\n    # Hàm làm phẳng ảnh\n    def flatten_image(image):\n        # Chuyển ảnh thành vector 1D\n        return image.flatten()\n\n    # Áp dụng làm phẳng ảnh cho mỗi dòng trong DataFrame\n    df['image_flat'] = df[image_col].apply(flatten_image)\n\n    image_flat = df['image_flat'].tolist()\n    label = df['label'].tolist()\n\n    return image_flat, label  # Trả về DataFrame chỉ chứa label và ảnh đã làm phẳng","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.275430Z","iopub.execute_input":"2025-05-20T13:18:01.275648Z","iopub.status.idle":"2025-05-20T13:18:01.289295Z","shell.execute_reply.started":"2025-05-20T13:18:01.275634Z","shell.execute_reply":"2025-05-20T13:18:01.288698Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def extract_sobel_features(image):\n    \"\"\"\n    Trích xuất đặc trưng Sobel từ ảnh màu.\n\n    Args:\n        image (np.ndarray): Ảnh đầu vào (BGR).\n\n    Returns:\n        np.ndarray: Vector đặc trưng Sobel magnitude được flatten.\n    \"\"\"\n    # Chuyển sang ảnh xám\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Tính Sobel theo hướng x và y\n    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n\n    # Tính magnitude gradient\n    magnitude = np.sqrt(sobelx**2 + sobely**2)\n\n    # Chuẩn hóa về 0-1\n    magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)\n\n    # Giảm kích thước để vector đặc trưng không quá lớn (ví dụ resize về 64x64)\n    magnitude_resized = cv2.resize(magnitude, (64, 64))\n\n    # Flatten thành vector 1 chiều\n    feature_vector = magnitude_resized.flatten()\n\n    return feature_vector\n\ndef extract_hsv_histogram(image, bins=(8, 8, 8)):\n    \"\"\"\n    Trích xuất histogram màu trong không gian HSV cho ảnh đầu vào.\n\n    Args:\n        image (np.ndarray): Ảnh màu (BGR).\n        bins (tuple): Số lượng bins cho kênh H, S, V tương ứng.\n\n    Returns:\n        np.ndarray: Vector histogram HSV đã chuẩn hóa.\n    \"\"\"\n    # Chuyển đổi ảnh từ BGR sang HSV\n    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    # Tính histogram 3 chiều cho kênh HSV\n    hist = cv2.calcHist([hsv_image], channels=[0, 1, 2],\n                        mask=None, histSize=bins,\n                        ranges=[0, 180, 0, 256, 0, 256])\n\n    # Chuẩn hóa histogram\n    hist = cv2.normalize(hist, hist).flatten()\n\n    return hist\n\ndef extract_hog_from_image(image):\n    \"\"\"\n    Trích xuất HOG từ ảnh màu (RGB hoặc BGR) bằng cách sử dụng tất cả các kênh.\n    \"\"\"\n    # Trích xuất HOG từ toàn bộ ảnh (bao gồm tất cả các kênh)\n    features = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False, channel_axis=-1)\n    return features\n\ndef extract_lbp_from_image(image, radius=3, n_points=24):\n    \"\"\"\n    Trích xuất LBP từ ảnh chưa flatten (2D hoặc 3D).\n    \"\"\"\n    # Chuyển ảnh sang ảnh xám nếu chưa\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n    \n    # Trả về histogram của LBP\n    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n    lbp_hist = lbp_hist.astype('float')\n    lbp_hist /= (lbp_hist.sum() + 1e-6)  # chuẩn hóa\n    return lbp_hist\n\ndef extract_features_from_images(images, features_to_extract=['hog', 'lbp', 'hsv', 'sobel']):\n    \"\"\"\n    Trích xuất các đặc trưng từ danh sách ảnh với lựa chọn đặc trưng.\n\n    Args:\n        images (list or np.ndarray): Danh sách ảnh.\n        features_to_extract (list of str): Danh sách các đặc trưng cần trích xuất.\n            Các giá trị hợp lệ: 'hog', 'lbp', 'hsv', 'sobel'.\n\n    Returns:\n        tuple hoặc np.ndarray: các mảng numpy tương ứng với đặc trưng được chọn theo thứ tự trong features_to_extract.\n    \"\"\"\n\n    hog_features_list = [] if 'hog' in features_to_extract else None\n    lbp_features_list = [] if 'lbp' in features_to_extract else None\n    hsv_features_list = [] if 'hsv' in features_to_extract else None\n    sobel_features_list = [] if 'sobel' in features_to_extract else None\n\n    for image in tqdm(images, desc=\"Extracting features from images\", total=len(images)):\n        if hog_features_list is not None:\n            hog_features = extract_hog_from_image(image)\n            hog_features_list.append(hog_features)\n        if lbp_features_list is not None:\n            lbp_features = extract_lbp_from_image(image)\n            lbp_features_list.append(lbp_features)\n        if hsv_features_list is not None:\n            hsv_features = extract_hsv_histogram(image)\n            hsv_features_list.append(hsv_features)\n        if sobel_features_list is not None:\n            sobel_features = extract_sobel_features(image)\n            sobel_features_list.append(sobel_features)\n\n    result = []\n    for f in features_to_extract:\n        if f == 'hog':\n            result.append(np.array(hog_features_list))\n        elif f == 'lbp':\n            result.append(np.array(lbp_features_list))\n        elif f == 'hsv':\n            result.append(np.array(hsv_features_list))\n        elif f == 'sobel':\n            result.append(np.array(sobel_features_list))\n        else:\n            raise ValueError(f\"Feature '{f}' không được hỗ trợ.\")\n\n    if len(result) == 1:\n        return result[0]\n    else:\n        return tuple(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.290073Z","iopub.execute_input":"2025-05-20T13:18:01.290308Z","iopub.status.idle":"2025-05-20T13:18:01.304011Z","shell.execute_reply.started":"2025-05-20T13:18:01.290292Z","shell.execute_reply":"2025-05-20T13:18:01.303411Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def flatten_and_normalize_batch(features):\n    \"\"\"\n    Làm phẳng và chuẩn hóa batch ảnh (nhiều ảnh trong một numpy array).\n    \"\"\"\n    # Làm phẳng từng ảnh trong batch (mỗi ảnh có dạng (height, width, channels))\n    flattened_features = features.reshape(features.shape[0], -1)  # Reshape từng ảnh thành vector 1D\n    \n    # Chuẩn hóa các đặc trưng cho toàn bộ batch ảnh\n    scaler = StandardScaler()\n    normalized_features = scaler.fit_transform(flattened_features)  # Chuẩn hóa các đặc trưng của batch ảnh\n    \n    return normalized_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.304656Z","iopub.execute_input":"2025-05-20T13:18:01.304949Z","iopub.status.idle":"2025-05-20T13:18:01.317673Z","shell.execute_reply.started":"2025-05-20T13:18:01.304924Z","shell.execute_reply":"2025-05-20T13:18:01.317020Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Huấn luyện và dự đoán","metadata":{}},{"cell_type":"code","source":"def manual_hyperparameter_tuning_cuml_with_tqdm(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Tune tham số thủ công cho 3 mô hình cuML (SVC, RF, KNN) có hiển thị tiến trình tqdm,\n    chỉ lưu tên model, tham số và điểm số tốt nhất cho từng model.\n    Giải phóng bộ nhớ GPU sau mỗi lần huấn luyện.\n\n    Args:\n        X_train, y_train: tập huấn luyện (cudf.DataFrame, cudf.Series)\n        X_val, y_val: tập validation để đánh giá\n\n    Returns:\n        results (dict): \n            {\n                'svm': {'best_params': ..., 'best_score': ...},\n                'random_forest': {'best_params': ..., 'best_score': ...},\n                'knn': {'best_params': ..., 'best_score': ...}\n            }\n    \"\"\"\n    models_param_grid = {\n    'svm': {\n        'model_class': cuSVC,\n        'param_grid': {\n            'kernel': ['linear', 'rbf', 'poly'],\n            'C': [0.01, 0.1],\n            'gamma': ['scale', 'auto'],\n            'degree': [2, 3],           # Chỉ dùng khi kernel='poly'\n            'coef0': [0.0, 0.1]         # Dùng với kernel='poly' hoặc 'sigmoid'\n        }\n    },\n    # 'random_forest': {\n    #     'model_class': cuRF,\n    #     'param_grid': {\n    #         'n_estimators': [50, 100, 150],\n    #         'max_depth': [10, 20, 30],  # ❌ Không dùng None\n    #         'max_features': [1.0]       # ✅ float ∈ (0.0, 1.0] hoặc int ≤ n_features\n    #     }\n    # },\n    'knn': {\n        'model_class': cuKNN,\n        'param_grid': {\n            'n_neighbors': [3, 5, 7, 10],\n            'weights': ['uniform'],  # cuML chỉ hỗ trợ 'uniform'\n            'metric': ['euclidean', 'manhattan', 'chebyshev'],\n            'algorithm': ['brute']   # cuML chỉ dùng brute force\n        }\n    }\n    }\n    # models_param_grid = {\n    #     'svm': {\n    #         'model_class': cuSVC,\n    #         'param_grid': {\n    #             'kernel': ['rbf'],\n    #             'C': [0.1],\n    #             'gamma': ['auto']\n    #         }\n    #     },\n    #     'random_forest': {\n    #         'model_class': cuRF,\n    #         'param_grid': {\n    #             'n_estimators': [100],\n    #             'max_depth': [20],\n    #             'min_samples_split': [5]\n    #         }\n    #     },\n    #     'knn': {\n    #         'model_class': cuKNN,\n    #         'param_grid': {\n    #             'n_neighbors': [5],\n    #             'weights': ['uniform'],\n    #             'metric': ['manhattan']\n    #         }\n    #     }\n    # }\n\n    results = {}\n\n    for model_name, config in models_param_grid.items():\n        ModelClass = config['model_class']\n        param_grid = config['param_grid']\n\n        keys, values = zip(*param_grid.items())\n        combinations = list(itertools.product(*values))\n\n        print(f\"Đang tune mô hình: {model_name}, số tổ hợp tham số: {len(combinations)}\")\n\n        best_score = -float('inf')\n        best_params = None\n\n        for v in tqdm(combinations, desc=f\"Tuning {model_name}\"):\n            params = dict(zip(keys, v))\n            model = ModelClass(**params)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_val)\n            score = accuracy_score(y_val.to_numpy(), y_pred.to_numpy())\n\n            if score > best_score:\n                best_score = score\n                best_params = params\n\n            # Giải phóng bộ nhớ GPU và Python sau khi dùng model\n            del model\n            gc.collect()\n            # Nếu cần reset GPU, có thể thêm ở đây, nhưng cẩn thận với cuda.close()\n\n        results[model_name] = {\n            'best_params': best_params,\n            'best_score': best_score\n        }\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.318337Z","iopub.execute_input":"2025-05-20T13:18:01.318595Z","iopub.status.idle":"2025-05-20T13:18:01.332438Z","shell.execute_reply.started":"2025-05-20T13:18:01.318579Z","shell.execute_reply":"2025-05-20T13:18:01.331885Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def initialize_best_model(results):\n    \"\"\"\n    Chọn mô hình có điểm best_score cao nhất trong results,\n    rồi khởi tạo mô hình đó với tham số best_params.\n\n    Args:\n        results (dict): cấu trúc như ví dụ của bạn\n\n    Returns:\n        model: mô hình cuML đã khởi tạo với tham số tốt nhất\n        model_name (str): tên mô hình được chọn\n        best_params (dict): tham số tốt nhất của mô hình\n    \"\"\"\n\n    # Map tên model sang lớp model cuML\n    model_classes = {\n        'svm': cuSVC,\n        'random_forest': cuRF,\n        'knn': cuKNN\n    }\n\n    # Tìm model có điểm số cao nhất\n    best_model_name = None\n    best_score = -float('inf')\n    for name, info in results.items():\n        if info['best_score'] > best_score:\n            best_score = info['best_score']\n            best_model_name = name\n\n    best_params = results[best_model_name]['best_params']\n    ModelClass = model_classes[best_model_name]\n\n    # Khởi tạo model với tham số tốt nhất\n    model = ModelClass(**best_params)\n\n    return model, best_model_name, best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.333151Z","iopub.execute_input":"2025-05-20T13:18:01.333386Z","iopub.status.idle":"2025-05-20T13:18:01.348373Z","shell.execute_reply.started":"2025-05-20T13:18:01.333363Z","shell.execute_reply":"2025-05-20T13:18:01.347651Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Đánh giá","metadata":{}},{"cell_type":"code","source":"class ClassificationEvaluator:\n    def __init__(self, y_true, y_pred, average='weighted'):\n        \"\"\"\n        Khởi tạo class đánh giá phân loại.\n\n        Args:\n            y_true (array-like): Nhãn thực tế.\n            y_pred (array-like): Nhãn dự đoán.\n            average (str): Cách tính trung bình cho precision, recall, f1 (default 'weighted').\n                           Có thể chọn 'micro', 'macro', 'weighted', 'binary' tùy bài toán.\n        \"\"\"\n        self.y_true = y_true\n        self.y_pred = y_pred\n        self.average = average\n\n    def accuracy(self):\n        return accuracy_score(self.y_true, self.y_pred)\n\n    def precision(self):\n        return precision_score(self.y_true, self.y_pred, average=self.average, zero_division=0)\n\n    def recall(self):\n        return recall_score(self.y_true, self.y_pred, average=self.average, zero_division=0)\n\n    def f1(self):\n        return f1_score(self.y_true, self.y_pred, average=self.average, zero_division=0)\n\n    def confusion_matrix(self):\n        cm = confusion_matrix(self.y_true, self.y_pred)\n        return cm\n\n    def classification_report(self):\n        \"\"\"\n        Trả về báo cáo chi tiết precision, recall, f1 cho từng lớp.\n        \"\"\"\n        return classification_report(self.y_true, self.y_pred, zero_division=0)\n\n    def summary(self):\n        \"\"\"\n        In ra các chỉ số chính.\n        \"\"\"\n        accuracy = self.accuracy()\n        precision = self.precision()\n        recall = self.recall()\n        f1_score = self.f1()\n        confusion_matrix = self.confusion_matrix()\n        print(\"Classification Evaluation Summary:\")\n        print(f\"Accuracy : {accuracy}\")\n        print(f\"Precision: {precision}\")\n        print(f\"Recall   : {recall}\")\n        print(f\"F1-score : {f1_score}\")\n        print(\"Confusion Matrix:\")\n        print(confusion_matrix)\n        return (accuracy, precision, recall, f1_score, confusion_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.349170Z","iopub.execute_input":"2025-05-20T13:18:01.349394Z","iopub.status.idle":"2025-05-20T13:18:01.362164Z","shell.execute_reply.started":"2025-05-20T13:18:01.349373Z","shell.execute_reply":"2025-05-20T13:18:01.361491Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Logger","metadata":{}},{"cell_type":"code","source":"def log_model_details(model_name, model_params, features, accuracy):\n    \"\"\"\n    Hàm ghi log thông tin về mô hình, tham số và độ chính xác.\n    \"\"\"\n    logger.info(f\"Model: {model_name}\")\n    logger.info(f\"Model Parameters: {model_params}\")\n    logger.info(f\"Features used: {features}\")\n    logger.info(f\"Accuracy: {accuracy:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.362928Z","iopub.execute_input":"2025-05-20T13:18:01.363202Z","iopub.status.idle":"2025-05-20T13:18:01.377113Z","shell.execute_reply.started":"2025-05-20T13:18:01.363187Z","shell.execute_reply":"2025-05-20T13:18:01.376498Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class utils:\n    @staticmethod\n    def save_array(filepath: str, array: np.ndarray):\n        \"\"\"\n        Lưu 1 mảng numpy vào file .npy (nhị phân, không nén).\n\n        Args:\n            filepath (str): Đường dẫn file lưu.\n            array (np.ndarray): Mảng numpy cần lưu.\n        \"\"\"\n        np.save(filepath, array)\n        print(f\"Đã lưu mảng vào {filepath}\")\n\n    @staticmethod\n    def load_array(filepath: str) -> np.ndarray:\n        \"\"\"\n        Đọc 1 mảng numpy từ file .npy.\n\n        Args:\n            filepath (str): Đường dẫn file đọc.\n\n        Returns:\n            np.ndarray: Mảng numpy đã đọc.\n        \"\"\"\n        array = np.load(filepath)\n        print(f\"Đã đọc mảng từ {filepath}\")\n        return array\n\n    @staticmethod\n    def save_arrays_compressed(filepath: str, **arrays):\n        \"\"\"\n        Lưu nhiều mảng numpy vào 1 file nén .npz.\n\n        Args:\n            filepath (str): Đường dẫn file lưu.\n            **arrays: Các mảng truyền theo tên biến, ví dụ: arr1=arr1, arr2=arr2\n        \"\"\"\n        np.savez_compressed(filepath, **arrays)\n        print(f\"Đã lưu {len(arrays)} mảng vào file nén {filepath}\")\n\n    @staticmethod\n    def load_arrays_compressed(filepath: str) -> dict:\n        \"\"\"\n        Đọc nhiều mảng numpy từ file nén .npz.\n\n        Args:\n            filepath (str): Đường dẫn file đọc.\n\n        Returns:\n            dict: Từ điển tên mảng và mảng numpy tương ứng.\n        \"\"\"\n        loaded = np.load(filepath)\n        arrays = {key: loaded[key] for key in loaded.files}\n        print(f\"Đã đọc {len(arrays)} mảng từ file nén {filepath}\")\n        return arrays","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.377763Z","iopub.execute_input":"2025-05-20T13:18:01.377963Z","iopub.status.idle":"2025-05-20T13:18:01.391169Z","shell.execute_reply.started":"2025-05-20T13:18:01.377944Z","shell.execute_reply":"2025-05-20T13:18:01.390644Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Plot ảnh sai","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\n\nclass FalsePredictionVisualizer:\n    def __init__(self, images, y_true, y_pred):\n        self.images = images\n        self.y_true = y_true\n        self.y_pred = y_pred\n\n    def get_false_predictions(self):\n        return [i for i in range(len(self.y_true)) if self.y_true[i] != self.y_pred[i]]\n\n    def display_false_predictions(self):\n        false_indices = self.get_false_predictions()\n        if len(false_indices) == 0:\n            print(\"Không có ảnh nào bị dự đoán sai.\")\n            return\n\n        cols = 5\n        rows = len(false_indices) // cols + (len(false_indices) % cols != 0)\n\n        plt.figure(figsize=(15, rows * 3))\n        for i, idx in enumerate(false_indices):\n            plt.subplot(rows, cols, i + 1)\n            plt.imshow(self.images[idx])\n            plt.title(f\"True: {self.y_true[idx]}, Pred: {self.y_pred[idx]}\")\n            plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n\n    def save_false_predictions_plot(self, save_path, prefix='false_pred'):\n        \"\"\"\n        Lưu toàn bộ các ảnh dự đoán sai thành một plot (hình ảnh lớn).\n\n        Args:\n            save_path (str): Đường dẫn file lưu hình (ví dụ 'false_predictions.png').\n            prefix (str): Tiền tố tên file (không bắt buộc).\n        \"\"\"\n        false_indices = self.get_false_predictions()\n        if len(false_indices) == 0:\n            print(\"Không có ảnh nào bị dự đoán sai để lưu.\")\n            return\n\n        cols = 5\n        rows = len(false_indices) // cols + (len(false_indices) % cols != 0)\n\n        plt.figure(figsize=(15, rows * 3))\n        for i, idx in enumerate(false_indices):\n            plt.subplot(rows, cols, i + 1)\n            plt.imshow(self.images[idx])\n            plt.title(f\"True: {self.y_true[idx]}, Pred: {self.y_pred[idx]}\")\n            plt.axis('off')\n        plt.tight_layout()\n\n        filename = f\"{prefix}_{save_path}\" if prefix else save_path\n        plt.savefig(filename)\n        plt.close()\n        print(f\"Đã lưu plot ảnh dự đoán sai vào '{filename}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.391878Z","iopub.execute_input":"2025-05-20T13:18:01.392070Z","iopub.status.idle":"2025-05-20T13:18:01.406673Z","shell.execute_reply.started":"2025-05-20T13:18:01.392051Z","shell.execute_reply":"2025-05-20T13:18:01.406071Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Logger","metadata":{}},{"cell_type":"code","source":"class LoggerManager:\n    def __init__(self, name: str, log_file: str = \"log.txt\", level=logging.INFO):\n        self.name = name\n        self.log_file = log_file\n        self.level = level\n        self.logger = logging.getLogger(name)\n\n        # Xóa handler cũ (nếu có) để tránh lặp log\n        if self.logger.hasHandlers():\n            self.logger.handlers.clear()\n\n        self._setup_logger()\n\n    def _setup_logger(self):\n        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n        # Ghi thêm (append) vào log file\n        file_handler = logging.FileHandler(self.log_file, mode='a')\n        file_handler.setFormatter(formatter)\n\n        # In ra console\n        stream_handler = logging.StreamHandler()\n        stream_handler.setFormatter(formatter)\n\n        self.logger.setLevel(self.level)\n        self.logger.addHandler(file_handler)\n        self.logger.addHandler(stream_handler)\n        self.logger.propagate = False\n\n    def get_logger(self) -> logging.Logger:\n        return self.logger\n\n    def clear_log(self):\n        \"\"\"Xóa toàn bộ nội dung file log.\"\"\"\n        if os.path.exists(self.log_file):\n            with open(self.log_file, 'w') as f:\n                pass  # hoặc f.truncate(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:01.407388Z","iopub.execute_input":"2025-05-20T13:18:01.407573Z","iopub.status.idle":"2025-05-20T13:18:01.421657Z","shell.execute_reply.started":"2025-05-20T13:18:01.407559Z","shell.execute_reply":"2025-05-20T13:18:01.421107Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Hàm thực thi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngit_token = user_secrets.get_secret(\"git_token\")\n\n!git clone https://hoivd:{git_token}@github.com/hoivd/tomato_leaf_classify.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:18.864405Z","iopub.execute_input":"2025-05-20T13:18:18.864687Z","iopub.status.idle":"2025-05-20T13:18:22.227861Z","shell.execute_reply.started":"2025-05-20T13:18:18.864665Z","shell.execute_reply":"2025-05-20T13:18:22.227084Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'tomato_leaf_classify'...\nremote: Enumerating objects: 9, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (6/6), done.\u001b[K\nremote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (9/9), 23.04 MiB | 33.66 MiB/s, done.\nResolving deltas: 100% (1/1), done.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## 1. Load hình ảnh","metadata":{}},{"cell_type":"code","source":"train_root_folder = \"/kaggle/input/tomatoleaf/tomato/train\"\ntrain_extractor = ImageFileLabelExtractor(train_root_folder)\ntrain_path_df = train_extractor.extract()\n\nval_root_folder = \"/kaggle/input/tomatoleaf/tomato/val\"\nval_extractor = ImageFileLabelExtractor(val_root_folder)\nval_path_df = val_extractor.extract()\n\ntrain_path_df.head()\nval_path_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:22.229208Z","iopub.execute_input":"2025-05-20T13:18:22.229452Z","iopub.status.idle":"2025-05-20T13:18:32.484453Z","shell.execute_reply.started":"2025-05-20T13:18:22.229429Z","shell.execute_reply":"2025-05-20T13:18:32.483900Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                           file_path                 label\n0  /kaggle/input/tomatoleaf/tomato/val/Tomato___L...  Tomato___Late_blight\n1  /kaggle/input/tomatoleaf/tomato/val/Tomato___L...  Tomato___Late_blight\n2  /kaggle/input/tomatoleaf/tomato/val/Tomato___L...  Tomato___Late_blight\n3  /kaggle/input/tomatoleaf/tomato/val/Tomato___L...  Tomato___Late_blight\n4  /kaggle/input/tomatoleaf/tomato/val/Tomato___L...  Tomato___Late_blight","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/tomatoleaf/tomato/val/Tomato___L...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/tomatoleaf/tomato/val/Tomato___L...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/tomatoleaf/tomato/val/Tomato___L...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/tomatoleaf/tomato/val/Tomato___L...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/tomatoleaf/tomato/val/Tomato___L...</td>\n      <td>Tomato___Late_blight</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"train_data_df = load_images_from_df_cv2(train_path_df)\nval_data_df = load_images_from_df_cv2(val_path_df)\n\ntrain_data_df.head()\nval_data_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:18:32.485141Z","iopub.execute_input":"2025-05-20T13:18:32.485353Z"}},"outputs":[{"name":"stderr","text":"Loading and resizing images:  94%|█████████▎| 9363/10000 [01:05<00:04, 139.83it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"mapping = {\n    'Tomato___Late_blight': 'late_blight',\n     'Tomato___healthy': 'healthy',\n     'Tomato___Early_blight': 'early_blight',\n     'Tomato___Septoria_leaf_spot': 'septoria_leaf_spot',\n     'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 'yellow_leaf_curl_virus',\n     'Tomato___Bacterial_spot': 'bacterial_spot',\n     'Tomato___Target_Spot': 'target_spot',\n     'Tomato___Tomato_mosaic_virus': 'mosaic_virus',\n     'Tomato___Leaf_Mold': 'leaf_mold',\n     'Tomato___Spider_mites Two-spotted_spider_mite': 'spider_mites'\n}\n\ntrain_data_df = edit_labels(train_data_df, mapping=mapping)\nval_data_df = edit_labels(val_data_df, mapping=mapping)\n\nprint(train_data_df['label'].unique())\nprint(val_data_df['label'].unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Thống kê dữ liệu","metadata":{}},{"cell_type":"code","source":"stats = LabelStats(train_data_df)\nstats.summary()\nstats.plot_class_distribution()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_images_with_label_column(train_data_df, grayscale=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Trích xuất đặc trưng","metadata":{}},{"cell_type":"code","source":"X_train, y_train = train_data_df['image'].tolist(), train_data_df['label'].tolist()\nX_val, y_val = val_data_df['image'].tolist(), val_data_df['label'].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_train_encoded = encoder.fit_transform(y_train)\ny_val_encoded = encoder.transform(y_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_orig = extract_features_from_images(X_train, features_to_extract=['lbp', 'hsv'])\nval_features_orig = extract_features_from_images(X_val, features_to_extract=['lbp', 'hsv'])\n# train_hog_features, train_lbp_features, train_hsv_features = extract_features_from_images(X_train)\n# val_hog_feature, val_lbp_features, val_hsv_features = extract_features_from_images(X_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_combined_features = np.hstack(train_features_orig)\nval_combined_features = np.hstack(val_features_orig)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features = flatten_and_normalize_batch(train_combined_features)\nval_features = flatten_and_normalize_batch(val_combined_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Huấn luyện và dự đoán","metadata":{}},{"cell_type":"code","source":"X_train_cudf = cudf.DataFrame.from_records(train_features)\ny_train_cudf = cudf.Series(y_train_encoded)\n\nX_val_cudf = cudf.DataFrame.from_records(val_features)\ny_val_cudf = cudf.Series(y_val_encoded)\n\nresults  = manual_hyperparameter_tuning_cuml_with_tqdm(\n    X_train_cudf, y_train_cudf, X_val_cudf, y_val_cudf)\n\nfor model_name, res in results.items():\n    print(f\"Model: {model_name}\")\n    print(f\"  Best params: {res['best_params']}\")\n    print(f\"  Best score: {res['best_score']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, model_name, params = initialize_best_model(results)\nprint(f\"Đã chọn mô hình: {model_name} với tham số: {params}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(X_train_cudf, y_train_cudf)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_predict = model.predict(X_val_cudf)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluator = ClassificationEvaluator(y_val_cudf.to_numpy(), y_predict.to_numpy())\naccuracy, precision, recall, f1_score, confusion_matrix = evaluator.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = np.unique(y_val_cudf.to_numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"disease_label = encoder.inverse_transform(labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confusion_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=disease_label, yticklabels=disease_label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Plot ảnh sai","metadata":{}},{"cell_type":"code","source":"images = val_data_df['image'].tolist()\ny_true = y_val\ny_pred = encoder.inverse_transform(y_predict.to_numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualizer = FalsePredictionVisualizer(images, y_true, y_pred)\n# visualizer.display_false_predictions()\nvisualizer.save_false_predictions_plot('false_predictions.png')","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import logging\n\n# # Khởi tạo logger\n# logger = logging.getLogger('model_logger')\n# logger.setLevel(logging.INFO)\n\n# # Tạo handler để ghi log vào file\n# file_handler = logging.FileHandler('model_training_log.log')\n# file_handler.setLevel(logging.INFO)\n\n# # Định dạng cho log\n# formatter = logging.Formatter('%(asctime)s - %(message)s')\n# file_handler.setFormatter(formatter)\n\n# # Thêm handler vào logger\n# logger.addHandler(file_handler)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}